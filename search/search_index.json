{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"vault-kms-plugin","text":"<p>A Kubernetes KMS Plugin that uses HashiCorp Vaults Transit Engine for securely encrypting Secrets, Config Maps and other Kubernetes Objects in etcd at rest (on disk).</p> <p> </p>"},{"location":"#why","title":"Why","text":"<p>HashiCorp Vault already offers useful Kubernetes integrations, such as the Vault Secrets Operator for populating Kubernetes secrets from Vault Secrets or the Vault Agent Injector for injecting Vault secrets into a Pod using a sidecar container approach.</p> <p>Wouldn't it be nice if you could also use your Vault server to encrypt Kubernetes secrets before they are written into etcd? The <code>vault-kubernetes-kms</code> plugin does exactly this!</p> <p>Since the key used for encrypting secrets is not stored in Kubernetes, an attacker who intends to get unauthorized access to the plaintext values would need to compromise etcd and the Vault server.</p>"},{"location":"#how-does-it-work","title":"How does it work?","text":"<p><code>vault-kubernetes-kms</code> is supposed to run as a static pod on every control plane node or on  that node where the <code>kube-apiserver</code> will run.</p> <p>The plugin creates a Unix-Socket and receive encryption requests through that socket from the <code>kube-apiserver</code>. The plugin will then use the specified Vault transit encryption key to encrypt the data and send it back to the <code>kube-apiserver</code>, who will then store the encrypted response in <code>etcd</code>.</p> <p>To do so, you will have to enable Data at Rest encryption, by configuring the <code>kube-apiserver</code> to use a <code>EncryptionConfiguration</code> (See https://falcosuessgott.github.io/vault-kubernetes-kms/configuration/ for more details).</p> <p> As a result of that, the <code>kube-apiserver</code> requires the <code>vault-kubernetes-kms</code> plugin to be up &amp; running before the <code>kube-apiserver</code> starts. To ensure this, setting a priority class in the plugins manifest (<code>\"priorityClassName: system-node-critical\"</code>) is recommended. </p> <p> <code>vault-kubernetes-kms</code> is in early stage! Running it in Production is not yet recommended. Im looking for early adopters in order to  gather important feedback. </p>"},{"location":"#features","title":"Features","text":"<ul> <li>support Vault Token Auth (not recommended for production), AppRole and Vault Kubernetes Auth using the Plugins Service Account</li> <li>support Kubernetes KMS Plugin v1 (deprecated since <code>v1.28.0</code>) &amp; v2 (stable in <code>v1.29.0</code>)</li> <li>automatic Token Renewal for avoiding Token expiry</li> <li>Exposes useful Prometheus Metrics</li> </ul>"},{"location":"concepts/","title":"Concepts","text":"<p>Read the official Kubernetes KMS docs for more details.</p>"},{"location":"concepts/#encryption-request","title":"Encryption Request","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#326ce5', 'primaryTextColor': '#fff', 'textColor': '#000'}}}%%\nsequenceDiagram\n    participant etcd\n    participant kubeapiserver\n    participant kmsplugin\n    participant externalkms\n    kubeapiserver-&gt;&gt;kmsplugin: encrypt request\n    alt using key hierarchy\n        kmsplugin-&gt;&gt;kmsplugin: encrypt DEK with local KEK\n        kmsplugin-&gt;&gt;externalkms: encrypt local KEK with remote KEK\n        externalkms-&gt;&gt;kmsplugin: encrypted local KEK\n        kmsplugin-&gt;&gt;kmsplugin: cache encrypted local KEK\n        kmsplugin-&gt;&gt;kubeapiserver: return encrypt response &lt;br/&gt; {\"ciphertext\": \"&lt;encrypted DEK&gt;\", key_id: \"&lt;remote KEK ID&gt;\", &lt;br/&gt; \"annotations\": {\"kms.kubernetes.io/local-kek\": \"&lt;encrypted local KEK&gt;\"}}\n    else not using key hierarchy\n        %% current behavior\n        kmsplugin-&gt;&gt;externalkms: encrypt DEK with remote KEK\n        externalkms-&gt;&gt;kmsplugin: encrypted DEK\n        kmsplugin-&gt;&gt;kubeapiserver: return encrypt response &lt;br/&gt; {\"ciphertext\": \"&lt;encrypted DEK&gt;\", key_id: \"&lt;remote KEK ID&gt;\", \"annotations\": {}}\n    end\n    kubeapiserver-&gt;&gt;etcd: store encrypt response and encrypted DEK</code></pre>"},{"location":"concepts/#decryption-request","title":"Decryption Request","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#326ce5', 'primaryTextColor': '#fff', 'textColor': '#000'}}}%%\nsequenceDiagram\n    participant kubeapiserver\n    participant kmsplugin\n    participant externalkms\n    %% if local KEK in annotations, then using hierarchy\n    alt encrypted local KEK is in annotations\n      kubeapiserver-&gt;&gt;kmsplugin: decrypt request &lt;br/&gt; {\"ciphertext\": \"&lt;encrypted DEK&gt;\", key_id: \"&lt;key_id gotten as part of EncryptResponse&gt;\", &lt;br/&gt; \"annotations\": {\"kms.kubernetes.io/local-kek\": \"&lt;encrypted local KEK&gt;\"}}\n        alt encrypted local KEK in cache\n            kmsplugin-&gt;&gt;kmsplugin: decrypt DEK with local KEK\n        else encrypted local KEK not in cache\n            kmsplugin-&gt;&gt;externalkms: decrypt local KEK with remote KEK\n            externalkms-&gt;&gt;kmsplugin: decrypted local KEK\n            kmsplugin-&gt;&gt;kmsplugin: decrypt DEK with local KEK\n            kmsplugin-&gt;&gt;kmsplugin: cache decrypted local KEK\n        end\n        kmsplugin-&gt;&gt;kubeapiserver: return decrypt response &lt;br/&gt; {\"plaintext\": \"&lt;decrypted DEK&gt;\", key_id: \"&lt;remote KEK ID&gt;\", &lt;br/&gt; \"annotations\": {\"kms.kubernetes.io/local-kek\": \"&lt;encrypted local KEK&gt;\"}}\n    else encrypted local KEK is not in annotations\n        kubeapiserver-&gt;&gt;kmsplugin: decrypt request &lt;br/&gt; {\"ciphertext\": \"&lt;encrypted DEK&gt;\", key_id: \"&lt;key_id gotten as part of EncryptResponse&gt;\", &lt;br/&gt; \"annotations\": {}}\n        kmsplugin-&gt;&gt;externalkms: decrypt DEK with remote KEK (same behavior as today)\n        externalkms-&gt;&gt;kmsplugin: decrypted DEK\n        kmsplugin-&gt;&gt;kubeapiserver: return decrypt response &lt;br/&gt; {\"plaintext\": \"&lt;decrypted DEK&gt;\", key_id: \"&lt;remote KEK ID&gt;\", &lt;br/&gt; \"annotations\": {}}\n    end</code></pre>"},{"location":"configuration/","title":"Configuration","text":"<p>Enabling KMS Encryption in your Cluster involves 3 steps:</p> <ol> <li>Preparing your Vaults Transit Engine &amp; Auth Method</li> <li>Deploying the <code>vault-kubernetes-kms</code> Plugin</li> <li>Enabling the encryption provider configuration for the <code>kube-apiserver</code>.</li> </ol>"},{"location":"configuration/#preparing-hashicorp-vault","title":"Preparing HashiCorp  Vault","text":"<p>The <code>vault-kms-plugin</code> requires a Vault Authentication, that allows encrypting and decrypting data with a given Transit Key.</p>"},{"location":"configuration/#transit-engine","title":"Transit Engine","text":"<p>Tip</p> <p>You can also perform these steps using Vaults UI or Vaults Terraform Provider (recommended).</p> <p>The following steps enable a transit engine <code>transit</code> and create transit key <code>kms</code>: <pre><code>$&gt; export VAULT_ADDR=\"https://vault.tld.de\"   # change to your Vaults API Address\n$&gt; export VAULT_TOKEN=\"hvs.XXXX\"             # change to a token allowed to create a transit engine and a transit key\n$&gt; vault secrets enable transit\n$&gt; vault write -f transit/keys/kms\n</code></pre></p> <p>Warning</p> <p>Absolutely make sure to either Backup (snapshot) your Vault in order to recover from failure, or export your KMS key prior usage (option: <code>allow-plaintext-backup</code>).</p> <p>If you loose the KMS key or recreate it, the kube-apiserver will not be able to decrypt any secrets.</p>"},{"location":"configuration/#vault-policy","title":"Vault Policy","text":"<p>The following Vault Policy lists the API paths required for the <code>vault-kubernetes-kms</code> plugin:</p> <p>Note</p> <p>This Policy assumes the transit engine is mounted at <code>transit</code> with a key named <code>kms</code>. In case your configuration differs, you will have to update the policy accordingly.</p> <pre><code># kms-policy.hcl\n# lookup the current tokens ttl for token renewal, is also in Vaults default policy\npath \"auth/token/lookup-self\" {\n    capabilities = [\"read\"]\n}\n\n# encrypt any data using the transit key\npath \"transit/encrypt/kms\" {\n   capabilities = [ \"update\" ]\n}\n\n# decrypt any data using the transit key\npath \"transit/decrypt/kms\" {\n   capabilities = [ \"update\" ]\n}\n\n# get the transit keys key versions for KMS key rotation\npath \"transit/keys/kms\" {\n   capabilities = [ \"read\" ]\n}\n</code></pre> <p>You can create the policy using <code>vault policy write kms ./kms-policy.hcl</code>.</p>"},{"location":"configuration/#vault-auth","title":"Vault Auth","text":"<p><code>vault-kubernetes-kms</code> suppors Token &amp; Approle Auth. Kubernetes Auth was removed (see falcosuessgott/vault-kubernetes-kms#81), since a static pod cannot reference any other API objects, such as Service Account, which are required for Kubernetes Auth.</p>"},{"location":"configuration/#approle-auth","title":"Approle Auth","text":"<pre><code># Follow https://developer.hashicorp.com/vault/docs/auth/approle\n# enable approle and create a role\n$&gt; vault auth enable approle\n$&gt; vault write auth/approle/role/kms token_num_uses=0 token_period=3600 token_policies=kms\n\n# get the role ID from the output of\n$&gt; vault read auth/approle/role/kms/role-id\n\n# get the secret ID from the output of\n$&gt; vault write -f auth/approle/role/kms/secret-id\n</code></pre>"},{"location":"configuration/#token-auth","title":"Token Auth","text":"<p>It is recommended, that the Vault token used for authentication is an orphaned and periodic token. Periodic tokens can be renewed within the period. An orphan token does not have a parent token and will not be revoked when the token that created it expires.</p> <pre><code># get the token from the output\n$&gt; vault token create -orphan -policy=\"kms\" -period=24h\n</code></pre>"},{"location":"configuration/#deploying-vault-kubernetes-kms","title":"Deploying <code>vault-kubernetes-kms</code>","text":""},{"location":"configuration/#container-images","title":"Container Images","text":"<p><code>vault-kubernetes-kms</code> is published on:</p> <ul> <li>ghcr.io: https://github.com/FalcoSuessgott/vault-kubernetes-kms/pkgs/container/vault-kubernetes-kms</li> <li>Docker Hub: https://hub.docker.com/r/falcosuessgott/vault-kubernetes-kms</li> </ul> <p>As of now, only <code>amd</code> (x86_64) images are published. If you need <code>arm</code> images, raise an issue.</p> <p>Info</p> <p>The plugin creates a Unix-Socket that is referenced in a <code>EncryptionConfiguration</code> manifest, which the <code>kube-apiserver</code> points to.</p> <p>That means, that the <code>kube-apiserver</code> will not properly start if the plugin is not up &amp; running. To ensure the plugin is running before the <code>kube-apiserver</code> it has to be deployed as a static Pod. To do so, we use <code>priorityClassName: system-node-critical</code> in the plugins manifest, to mark the Pod as critical (https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/#marking-pod-as-critical).</p>"},{"location":"configuration/#cli-args-environment-variables","title":"CLI Args &amp; Environment Variables","text":"<p>List of required and optional CLI args/env vars. Furthermore, all of Vaults Env Vars are supported:</p> <p>Vault Server:</p> <ul> <li>(Required): <code>-vault-address</code> (<code>VAULT_KMS_VAULT_ADDR</code>)</li> <li>(Optional): <code>-vault-namespace</code> (<code>VAULT_KMS_VAULT_NAMESPACE</code>)</li> </ul> <p>Vault Transit Engine:</p> <ul> <li>(Optional): <code>-transit-mount</code> (<code>VAULT_KMS_TRANSIT_MOUNT</code>); default: <code>\"transit\"</code></li> <li>(Optional): <code>-transit-key</code> (<code>VAULT_KMS_TRANSIT_KEY</code>); default: <code>\"kms\"</code></li> </ul> <p>If Vault Token Auth:</p> <ul> <li>(Required): <code>-auth-method=\"token\"</code> (<code>VAULT_KMS_AUTH_METHOD</code>)</li> <li>(Required): <code>-token</code> (<code>VAULT_KMS_VAULT_TOKEN</code>)</li> </ul> <p>If Vault Approle Auth:</p> <ul> <li>(Required): <code>-auth-method=\"approle\"</code> (<code>VAULT_KMS_AUTH_METHOD</code>)</li> <li>(Required): <code>-approle-role-id</code> (<code>VAULT_KMS_APPROLE_ROLE_ID</code>)</li> <li>(Required): <code>-approle-secret-id</code> (<code>VAULT_KMS_APPROLE_SECRET_ID</code>)</li> <li>(Optional): <code>-approle-mount</code> (<code>VAULT_KMS_APPROLE_MOUNT</code>); default: <code>\"approle\"</code></li> </ul> <p>Lease Refreshing Settings:</p> <ul> <li>(Optional): <code>-token-refresh-interval</code> (<code>VAULT_KMS_TOKEN_REFRESH_INTERVAL</code>); default: <code>\"60s\"</code></li> <li>(Optional): <code>-token-renewal</code> (<code>VAULT_KMS_TOKEN_RENEWAL</code>); default: <code>\"3600\"</code></li> </ul> <p>Warning</p> <p><code>vault_kubernetes_kms</code> automatically renewals the lease to avoid expired/revoked leases.</p> <p>It does so by periodically comparing the current TTL with the tokens creation TTL (See https://developer.hashicorp.com/vault/tutorials/get-started/introduction-tokens#token-metadata). The check will be run periodically in the interval specified with <code>-token-refresh-interval</code> (default: <code>60s</code>).</p> <p>If the current TTL is less than half of the creation TTL, then the current lease will be renewed for the amount of seconds defined in <code>-token-renewal</code> (default: <code>3600</code> seconds, <code>1h</code>).</p> <p>If, for whatever reason the token renewal fails, then the configured auth method will be executed again. Meanwhile this works well with Approle authentication, token auth will most likely fail, due to the token being revoked. In that case, you should make sure to provide a periodic token.</p> <p>General:</p> <ul> <li>(Optional): <code>-socket</code> (<code>VAULT_KMS_SOCKET</code>); default: <code>unix:///opt/kms/vaultkms.socket\"</code></li> <li>(Optional): <code>-force-socket-overwrite</code> (<code>FORCE_SOCKET_OVERWRITE</code>); default: <code>false</code>.</li> </ul> <p>Warning</p> <p>Use <code>-force-socket-overwrite</code> with caution. This will delete whatever filetype exists at the value specified in <code>-socket</code> path on the Control plane node.</p> <p>When <code>vault-kubernetes-kms</code> crashes, it is not guaranteed that the socket-file will always be removed. For those scenarios <code>-force-socket-overwrite</code> was introduced to allow a smooth re-deployment of the plugin and not having to manually delete the stale socket file on the control plane node.</p> <ul> <li>(Optional): <code>-debug</code> (<code>VAULT_KMS_DEBUG</code>)</li> <li>(Optional): <code>-health-port</code> (<code>VAULT_KMS_HEALTH_PORT</code>); default: <code>\":8080\"</code></li> <li>(Optional): <code>-disable-v1</code> (<code>VAULT_KMS_DISABLE_V1</code>); default: <code>\"true\"</code></li> </ul>"},{"location":"configuration/#example-vault-token-auth","title":"Example Vault Token Auth","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: vault-kubernetes-kms\n  namespace: kube-system\nspec:\n  priorityClassName: system-node-critical\n  hostNetwork: true\n  containers:\n    - name: vault-kubernetes-kms\n      image: falcosuessgott/vault-kubernetes-kms:latest\n      # either specify CLI Args or env vars (look above)\n      command:\n        - /vault-kubernetes-kms\n        - -vault-address=https://vault.server.de\n        - -auth-method=token\n        - -token=hvs.ABC123\n      volumeMounts:\n        - name: kms\n          mountPath: /opt/kms\n      livenessProbe:\n        httpGet:\n          path: /health\n          port: 8080\n      readinessProbe:\n        httpGet:\n          path: /live\n          port: 8080\n      resources:\n        requests:\n          cpu: 100m\n          memory: 128Mi\n        limits:\n          cpu: 2\n          memory: 256Mi\n  volumes:\n    - name: kms\n      hostPath:\n        path: /opt/kms\n</code></pre>"},{"location":"configuration/#example-vault-approle-auth","title":"Example Vault Approle Auth","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: vault-kubernetes-kms\n  namespace: kube-system\nspec:\n  priorityClassName: system-node-critical\n  hostNetwork: true\n  containers:\n    - name: vault-kubernetes-kms\n      image: falcosuessgott/vault-kubernetes-kms:latest\n        # either specify CLI Args or env vars (look above)\n      command:\n        - /vault-kubernetes-kms\n        - -vault-address=https://vault.server.de\n        - -auth-method=approle\n        - -approle-role-id=XXXX\n        - -approle-secret-id=XXXX\n      volumeMounts:\n        - name: kms\n          mountPath: /opt/kms\n      livenessProbe:\n        httpGet:\n          path: /health\n          port: 8080\n      readinessProbe:\n        httpGet:\n          path: /live\n          port: 8080\n      resources:\n        requests:\n          cpu: 100m\n          memory: 128Mi\n        limits:\n          cpu: 2\n          memory: 256Mi\n  volumes:\n    - name: kms\n      hostPath:\n        path: /opt/kms\n</code></pre>"},{"location":"configuration/#example-tls-configuration","title":"Example TLS Configuration","text":"<p>It is recommended, to specify the CA cert that issued the vault server certificate, to connect to the Vault Server using HTTPS.</p> <p>To do sou you would have to copy the PEM-encoded CA Cert on the node where the plugin is running and then adjust the manifest to mount that directory as a volume and then use that path and specify it in the <code>\"VAULT_CACERT\"</code> environment variable.</p> <p>Note</p> <p>Note that you cant reference a secret here, because static Pod cant reference any other Kubernetes API Objects.</p> <p>Example:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: vault-kubernetes-kms\n  namespace: kube-system\nspec:\n  priorityClassName: system-node-critical\n  hostNetwork: true\n  containers:\n    - name: vault-kubernetes-kms\n      image: falcosuessgott/vault-kubernetes-kms:latest\n      # either specify CLI Args or env vars (look above)\n      command:\n        - /vault-kubernetes-kms\n        - --vault-address=https://vault.server.de\n        - -auth-method=token\n        - -token=XXXX\n      env:\n        # add vaults CA file via env vars\n        - name: VAULT_CACERT\n          value: /opt/kms/ca.crt\n      volumeMounts:\n        # mount the volume\n        - name: kms\n          mountPath: /opt/kms\n      livenessProbe:\n        httpGet:\n          path: /health\n          port: 8080\n      readinessProbe:\n        httpGet:\n          path: /live\n          port: 8080\n      resources:\n        requests:\n          cpu: 100m\n          memory: 128Mi\n        limits:\n          cpu: 2\n          memory: 256Mi\n  volumes:\n    - name: kms\n      hostPath:\n        # CA cert is located on node at /opt/kms/ca.crt\n        path: /opt/kms\n</code></pre> <p>After applying you check the pods logs for any errors:</p> <pre><code>$&gt; kubectl logs -n kube-system vault-kubernetes-kms\n{\"level\":\"info\",\"timestamp\":\"2024-01-31T13:18:24.852Z\",\"caller\":\"cmd/main.go:111\",\"message\":\"starting kms plugin\",\"socket\":\"unix:///opt/vaultkms.socket\",\"debug\":false,\"vault-address\":\"http://host.minikube.internal:8200\",\"vault-namespace\":\"\",\"vault-token\":\"\",\"vault-k8s-mount\":\"kubernetes\",\"vault-k8s-role\":\"kms\",\"vault-transit-mount\":\"transit\",\"vault-transit-key\":\"kms\"}\n{\"level\":\"info\",\"timestamp\":\"2024-01-31T13:18:24.898Z\",\"caller\":\"cmd/main.go:144\",\"message\":\"Successfully authenticated to vault\"}\n{\"level\":\"info\",\"timestamp\":\"2024-01-31T13:18:24.898Z\",\"caller\":\"cmd/main.go:151\",\"message\":\"Successfully created unix socket\",\"socket\":\"/opt/vaultkms.socket\"}\n{\"level\":\"info\",\"timestamp\":\"2024-01-31T13:18:24.898Z\",\"caller\":\"cmd/main.go:158\",\"message\":\"Listening for connection\"}\n{\"level\":\"info\",\"timestamp\":\"2024-01-31T13:18:24.898Z\",\"caller\":\"cmd/main.go:169\",\"message\":\"Successfully registered kms plugin\"}\n</code></pre>"},{"location":"configuration/#enabling-the-encryption-provider-configuration-for-the-kube-apiserver","title":"Enabling the encryption provider configuration for the <code>kube-apiserver</code>.","text":""},{"location":"configuration/#determine-which-kms-version-to-use","title":"Determine which KMS version to use","text":"<p>Since the <code>vault-kms-plugin</code> supports both KMS versions, you would have to determine, which KMS Plugin version works for your setup:</p> <p>From the Kubernetes documentation:</p> <p>Note</p> <p>The version of Kubernetes that you need depends on which KMS API version you have selected. Kubernetes recommends using KMS v2.</p> <p>If you selected KMS API v2, you should use Kubernetes v1.29 (if you are running a different version of Kubernetes that also supports the v2 KMS API, switch to the documentation for that version of Kubernetes).</p> <p>If you selected KMS API v1 to support clusters prior to version v1.27 or if you have a legacy KMS plugin that only supports KMS v1, any supported Kubernetes version will work. This API is deprecated as of Kubernetes v1.28. Kubernetes does not recommend the use of this API.</p>"},{"location":"configuration/#encryption-provider-configuration","title":"Encryption Provider configuration","text":"<p>Copy the appropriate encryption provider configuration to your control plane nodes (e.g. <code>/opt/kms/encryption_provider_config.yml</code>):</p>"},{"location":"configuration/#kms-plugin-v1","title":"KMS Plugin v1","text":"<pre><code>---\nkind: EncryptionConfiguration\napiVersion: apiserver.config.k8s.io/v1\nresources:\n  - resources:\n      - secrets\n    providers:\n      - kms:\n          name: vault\n          endpoint: unix:///opt/kms/vaultkms.socket\n      - identity: {}\n</code></pre>"},{"location":"configuration/#kms-plugin-v2","title":"KMS Plugin v2","text":"<pre><code>---\nkind: EncryptionConfiguration\napiVersion: apiserver.config.k8s.io/v1\nresources:\n  - resources:\n      - secrets\n    providers:\n      - kms:\n          apiVersion: v2\n          name: vault-kubernetes-kms\n          endpoint: unix:///opt/kms/vaultkms.socket\n      - identity: {}\n</code></pre>"},{"location":"configuration/#modify-the-kube-api-server-manifest","title":"Modify the <code>kube-api-server</code> Manifest","text":"<p>Last but not least, you would have to enable the encryption provider config for the <code>kube-apiserver</code>. This steps depends on wether your control plane components run as a systemd daemon or as static Pod on your control plane nodes (usually located at <code>/etc/kubernetes/manifests</code>).</p> <p>Either way, the following changes need to be done:</p> <pre><code># ...\nspec:\n  containers:\n  - command:\n    - kube-apiserver\n    # enabling the encryption provider config\n    - --encryption-provider-config=/opt/kms/encryption_provider_config.yml\n# ...\n</code></pre> <p>Also you will have to mount the <code>/opt</code> directory, for accessing the socket, that is created by the plugin and the encryption provider config:</p> <pre><code># ....\nvolumeMounts:\n    - name: kms\n      mountPath: /opt/kms\nvolumes:\n  - name: kms\n    hostPath:\n      path: /opt/kms\n# ....\n</code></pre> <p>Once changes are made, the <code>kube-apiserver</code> will restart (if static pod) or you restart the SystemD Unit.</p> <p>You then can use <code>watch</code> to monitor the pods:</p> <pre><code>$&gt; watch kubectl get pod -n kube-system\nNAME                               READY   STATUS    RESTARTS       AGE\ncoredns-76f75df574-dwtfv           1/1     Running   0              151m\netcd-minikube                      1/1     Running   0              152m\nkube-apiserver-minikube            0/1     Running   1              50s  # restarted\nkube-controller-manager-minikube   1/1     Running   0              152m\nkube-proxy-hqpmw                   1/1     Running   0              151m\nkube-scheduler-minikube            1/1     Running   0              152m\nstorage-provisioner                1/1     Running   7 (118m ago)   152m\nvault-kubernetes-kms               1/1     Running   0              49m\n</code></pre> <p>You should now see in the plugin logs that encryption and decryption requests are coming:</p> <pre><code>$&gt; kubectl logs -n kube-system vault-kubernetes-kms\n{\"level\":\"info\",\"timestamp\":\"2024-01-31T13:31:29.159Z\",\"caller\":\"kms/plugin.go:112\",\"message\":\"encryption request\",\"request_id\":\"f1eb6db8-390e-4bd4-8481-c56e46c1d685\"}\n</code></pre>"},{"location":"configuration/#verify-secret-encryption","title":"Verify Secret Encryption","text":"<p>Finally, create a secret to verify everything works correctly:</p> <pre><code>$&gt; kubectl create secret generic secret-encrypted -n default --from-literal=key=value\nsecret/secret-encrypted created\n</code></pre> <p>If the secret creation fails, something does not work!</p> <p>You could also check the etcd storage for the encrypted data:</p> <pre><code># this works only on minikube, you would have to update the params according to your cluster config\n$&gt; kubectl -n kube-system exec etcd-minikube -- sh -c \"ETCDCTL_API=3 etcdctl\n    --endpoints=https://127.0.0.1:2379 \\\n    --cert /var/lib/minikube/certs/etcd/server.crt \\\n    --key /var/lib/minikube/certs/etcd/server.key \\\n    --cacert /var/lib/minikube/certs/etcd/ca.crt \\\n    get /registry/secrets/default/secret-encrypted\" | hexdump -C\n00000000  2f 72 65 67 69 73 74 72  79 2f 73 65 63 72 65 74  |/registry/secret|\n00000010  73 2f 64 65 66 61 75 6c  74 2f 73 65 63 72 65 74  |s/default/secret|\n00000020  2d 65 6e 63 72 79 70 74  65 64 0a 6b 38 73 3a 65  |-encrypted.k8s:e|\n00000030  6e 63 3a 6b 6d 73 3a 76  32 3a 76 61 75 6c 74 3a  |nc:kms:v2:vault:|\n00000040  0a a4 02 2f 0b 6f 44 78  f8 9b 2c 23 b7 d8 99 e0  |.../.oDx..,#....|\n00000050  6f 2b 71 48 00 27 08 31  58 c2 2d 9c 8c 41 54 87  |o+qH.'.1X.-..AT.|\n00000060  cd 38 7e 90 78 ea 5d 3d  81 5e d4 67 ac f9 11 25  |.8~.x.]=.^.g...%|\n00000070  ca eb 68 f3 ae 43 e0 eb  ce 0f fa dc d2 97 91 bb  |..h..C..........|\n00000080  e4 04 2f fe 7e f7 83 0f  ef cc 4c 5e 41 f2 3f 42  |../.~.....L^A.?B|\n00000090  5a 47 4d e4 3b 6d dc 78  e2 a3 65 f8 bb 84 88 e5  |ZGM.;m.x..e.....|\n000000a0  9f 34 1f 53 d2 2a 59 8f  ac 77 a4 58 57 e9 4b 06  |.4.S.*Y..w.XW.K.|\n000000b0  f8 e9 80 f1 cf 96 aa 50  1a 24 1c 6a f6 6c e7 2d  |.......P.$.j.l.-|\n000000c0  58 ec 30 13 27 6c 4d 43  f5 60 07 8d 11 6f 43 4c  |X.0.'lMC.`...oCL|\n000000d0  ae 2b f0 69 01 18 05 a0  22 9b e9 9b 10 c6 83 7f  |.+.i....\".......|\n000000e0  bb 5c 3e 89 cb 33 68 52  fc 16 c0 37 0a f9 8e 5d  |.\\&gt;..3hR...7...]|\n000000f0  7c 88 4f cd 02 f1 94 c9  69 52 d7 bc 61 7d b0 aa  ||.O.....iR..a}..|\n00000100  bd 4e 7b a1 d9 91 79 17  c8 2a 3d ec 1c a0 60 8e  |.N{...y..*=...`.|\n00000110  73 1c 1e 4e 1b 09 81 fb  3a 2b 6c 1c a4 87 7c 3f  |s..N....:+l...|?|\n00000120  f2 6a 21 1b f8 42 d4 33  57 64 da be 47 43 a8 92  |.j!..B.3Wd..GC..|\n00000130  09 95 61 1b cd 97 5c 30  f1 e5 bf 21 ba 82 21 68  |..a...\\0...!..!h|\n00000140  3a 14 8b e9 0e 8a 83 6b  ed de 24 f3 5b fd 02 f0  |:......k..$.[...|\n00000150  bd 22 b1 ea f3 15 13 9d  c2 a9 01 cf 36 78 5a 77  |.\"..........6xZw|\n00000160  fd 83 fe 46 0e 49 bf 12  0a 31 37 30 36 37 30 37  |...F.I...1706707|\n00000170  37 37 34 1a 59 76 61 75  6c 74 3a 76 31 3a 68 66  |774.Yvault:v1:hf|\n00000180  54 61 73 58 37 39 4c 63  38 37 68 7a 38 48 77 31  |TasX79Lc87hz8Hw1|\n00000190  6a 4e 6d 57 6a 6f 65 56  39 4d 55 73 43 4c 2f 74  |jNmWjoeV9MUsCL/t|\n000001a0  6d 34 6d 78 4e 6a 41 46  2b 51 51 4a 72 36 4c 6b  |m4mxNjAF+QQJr6Lk|\n000001b0  36 52 69 6a 32 7a 62 57  73 57 44 44 70 65 30 6b  |6Rij2zbWsWDDpe0k|\n000001c0  39 68 59 72 4a 4b 39 2f  55 6c 30 69 79 42 28 01  |9hYrJK9/Ul0iyB(.|\n000001d0  0a                                                |.|\n000001d1\n</code></pre>"},{"location":"development/","title":"Development","text":"<p>This guide walks you through the required steps of building and running this plugin locally with and without Kubernetes.</p>"},{"location":"development/#local-development-without-kubernetes","title":"Local Development without Kubernetes","text":"<p>You don't have to deploy the plugin in a Kubernetes Cluster, you can just execute it locally, given you have a Vault running:</p> <pre><code>$&gt; make setup-vault\n$&gt; go run main.go -vault-address=http://127.0.0.1:8200 -auth-method=token -token=root -socket=unix:///tmp/kms.socket\n{\"level\":\"info\",\"timestamp\":\"2024-08-25T15:36:19.233+1000\",\"caller\":\"cmd/plugin.go:154\",\"message\":\"starting kms plugin\",\"auth-method\":\"token\",\"socket\":\"unix:///tmp/kms.socket\",\"debug\":false,\"vault-address\":\"http://127.0.0.1:8200\",\"vault-namespace\":\"\",\"transit-engine\":\"transit\",\"transit-key\":\"kms\",\"health-port\":\":8080\",\"disable-v1\":false}\n{\"level\":\"info\",\"timestamp\":\"2024-08-25T15:36:19.235+1000\",\"caller\":\"cmd/plugin.go:167\",\"message\":\"Successfully authenticated to vault\"}\n{\"level\":\"info\",\"timestamp\":\"2024-08-25T15:36:19.235+1000\",\"caller\":\"cmd/plugin.go:174\",\"message\":\"Successfully dialed to unix domain socket\",\"socket\":\"unix:///tmp/kms.socket\"}\n{\"level\":\"info\",\"timestamp\":\"2024-08-25T15:36:19.235+1000\",\"caller\":\"cmd/plugin.go:184\",\"message\":\"Successfully registered kms plugin v1\"}\n{\"level\":\"info\",\"timestamp\":\"2024-08-25T15:36:19.235+1000\",\"caller\":\"cmd/plugin.go:191\",\"message\":\"Successfully registered kms plugin v2\"}\n</code></pre> <p>In order to send encryption and decryption requests you can use the client CLI tool in <code>cmd/v2_Client/main.go</code>. This tool simply connects to the plugin and encrypts a given string and decrypts it back to its plaintext version:</p> <pre><code>$&gt; go run cmd/v2_client/main.go encrypt this string\n\"encrypt this string\" -&gt; \"dmF1bHQ6djE6VzJMcHp4UmJMdHV4TWNnUnVWMWJQQzBHMWZ0VkwvZFVUMldLRzQ0RUtCa1VJcjVwVjgxMFd3T29pRmVhQzVNPQ==\" -&gt; \"encrypt this string\"\n</code></pre>"},{"location":"development/#local-development-with-kubernetes","title":"Local Development with Kubernetes","text":"<p>The following steps describe how to build &amp; run the vault-kubernetes-kms completely locally using <code>docker</code>, <code>vault</code> &amp; <code>kind</code>.</p>"},{"location":"development/#requirements","title":"Requirements","text":"<p>Obviously you will need all the tools mentioned above installed. Also this setup is only tested on Linux and MacOS.</p>"},{"location":"development/#components","title":"Components","text":"<p>Basically, we will need:</p> <ol> <li>A local Vault server initialized &amp; unsealed and with a transit engine enabled as well as a transit key created.</li> <li>A local (docker) registry so kind can pull the currently unreleased <code>vault-kubernetes-kms</code> image.</li> <li>A local Kubernetes Cluster (kind) configured to use the local registry as well as the required settings for the kube-apiservers encryption provider config.</li> </ol>"},{"location":"development/#1-local-vault-server-using-vault","title":"1. Local Vault Server using <code>vault</code>","text":"<p>The following snippets sets up a local vault development server and creates a transit engine as well as a transit key.</p> <p>This script is located in <code>scripts/vault.sh</code> and is available via <code>make setup-vault</code>:</p> <pre><code>#!/usr/bin/env bash\nset -x\n\ncommand -v vault &gt;/dev/null 2&gt;&amp;1 || { echo \"vault is not installed.  Aborting.\" &gt;&amp;2; exit 1; }\n\n# kill any remaining vault instances\nkill $(pgrep -x vault) || true\n\n# start developemnt vault\nnohup vault server -dev -dev-listen-address=0.0.0.0:8200 -dev-root-token-id=root 2&gt; /dev/null &amp;\nsleep 3\n\n# auth to vault\nexport VAULT_ADDR=\"http://127.0.0.1:8200\"\nexport VAULT_SKIP_VERIFY=\"true\"\nexport VAULT_TOKEN=\"root\"\n\n# enable transit engine\nvault secrets enable transit\nvault write -f transit/keys/kms\n\n# write vault policy\nvault policy write kms - &lt;&lt;EOF\n# perform a simple vault login test\npath \"auth/token/lookup-self\" {\n    capabilities = [\"read\"]\n}\n\n# encrypt\npath \"transit/encrypt/kms\" {\n   capabilities = [ \"update\" ]\n}\n\n# decrypt\npath \"transit/decrypt/kms\" {\n   capabilities = [ \"update\" ]\n}\n\n# get key version\npath \"transit/keys/kms\" {\n   capabilities = [ \"read\" ]\n}\nEOF\n</code></pre>"},{"location":"development/#2-local-containerdocker-registry-using-docker","title":"2. Local Container/Docker Registry using <code>docker</code>","text":"<p>The following snippet, starts a local container registry, builds the current commits <code>vault-kubernetes-kms</code> image and tags &amp; pushes the image to the local registry.</p> <p>This script is located in <code>scripts/local-registry.sh</code> and is available via <code>make setup-registry</code>:</p> <pre><code>#!/usr/bin/env bash\nset -xeu\n\ncommand -v docker &gt;/dev/null 2&gt;&amp;1 || { echo \"docker is not installed.  Aborting.\" &gt;&amp;2; exit 1; }\n\nREGISTRY_NAME=registry\nREGISTRY_PORT=5000\nIMAGE_NAME=vault-kubernetes-kms\n\necho \"====&gt; create kind docker network\"\ndocker network create kind || true\n\necho \"====&gt; creating registry container unless it already exists\"\n[[ $(docker ps -f \"name=${REGISTRY_NAME}\" --format '{{.Names}}') == $REGISTRY_NAME ]] || docker run -d --restart=always -p \"${REGISTRY_PORT}:5000\" --name \"${REGISTRY_NAME}\" registry:2\n\necho \"====&gt; building container ...\"\ndocker build --no-cache -t \"${IMAGE_NAME}:latest\" .\n\necho \"====&gt; tagging container ...\"\ndocker tag \"${IMAGE_NAME}:latest\" \"localhost:${REGISTRY_PORT}/${IMAGE_NAME}:latest\"\n\necho \"====&gt; pushing container to local registry ....\"\ndocker push \"localhost:${REGISTRY_PORT}/${IMAGE_NAME}:latest\"\n\necho \"====&gt; connecting registry to kind ....\"\ndocker network connect kind \"${REGISTRY_NAME}\" || true\n</code></pre>"},{"location":"development/#3-local-kubernetes-cluster-using-kind","title":"3. Local Kubernetes Cluster using <code>kind</code>","text":"<p>Last but not least, we combine the above mentioned tools and consume them with <code>kind</code></p> <p>The following <code>kind</code>-config configures the local running registry, copies the encryption provider config and the <code>vault-kubernetes-kms</code> static pod manifest to the Kubernetes host and patches the <code>kube-apiserver</code> for using the provided encryption provider config.</p> <p>This can be run via <code>make setup-kind</code>, which runs <code>kind create cluster --name=kms --config scripts/kind-config.yaml</code> under the hood:</p> <pre><code>kind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\ncontainerdConfigPatches:\n# add a local docker registry to containerd\n# the registry is run via  a separated docker container\n- |-\n  [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"localhost:5000\"]\n    endpoint = [\"http://registry:5000\"]\nnodes:\n- role: control-plane\n  extraMounts:\n  # mount encryption provider config available on all cp nodes\n  - containerPath: /etc/kubernetes/encryption_provider_config_v2.yaml\n    hostPath: scripts/encryption_provider_config_v2.yml\n    readOnly: true\n    propagation: None\n  # vault-kubernetes-kms as a static Pod\n  - containerPath: /etc/kubernetes/manifests/vault-kubernetes-kms.yaml\n    hostPath: scripts/vault-kubernetes-kms.yml\n    readOnly: true\n    propagation: None\n  # patch kube-apiserver\n  kubeadmConfigPatches:\n    - |\n      kind: ClusterConfiguration\n      apiServer:\n        extraArgs:\n          encryption-provider-config: \"/etc/kubernetes/encryption_provider_config_v2.yaml\"\n        extraVolumes:\n        - name: encryption-config\n          hostPath: \"/etc/kubernetes/encryption_provider_config_v2.yaml\"\n          mountPath: \"/etc/kubernetes/encryption_provider_config_v2.yaml\"\n          readOnly: true\n          pathType: File\n        - name: socket\n          hostPath: \"/opt/kms\"\n          mountPath: \"/opt/kms\"\n</code></pre> <p>the <code>vault-kubernetes-kms</code> manifest:</p> <p>for development purposes, we use the vault dev servers configured root token (<code>\"root\"</code>):</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: vault-kubernetes-kms\n  namespace: kube-system\n  labels:\n    app: vault-kubernetes-kms\nspec:\n  priorityClassName: system-node-critical\n  hostNetwork: true\n  containers:\n    - name: vault-kubernetes-kms\n      image: localhost:5000/vault-kubernetes-kms:latest\n      imagePullPolicy: IfNotPresent\n      command:\n        - /vault-kubernetes-kms\n        - -vault-address=http://host.docker.internal:8200\n        - -auth-method=token\n        - -token=root\n      volumeMounts:\n        # mount /opt/kms host directory\n        - name: kms\n          mountPath: /opt/kms\n      livenessProbe:\n      httpGet:\n          path: /health\n          port: 8080\n      readinessProbe:\n        httpGet:\n          path: /live\n          port: 8080\n      resources:\n        requests:\n          cpu: 100m\n          memory: 128Mi\n        limits:\n          cpu: 2\n          memory: 256Mi\n  volumes:\n    # mount /opt/kms host directory\n    - name: kms\n      hostPath:\n        path: /opt/kms\n</code></pre>"},{"location":"development/#putting-it-together","title":"Putting it together","text":"<p>So if you wanna run all components locally and build the current commits plugin, it would look like this:</p> <pre><code>$&gt; make setup-vault\n$&gt; make setup-registry\n$&gt; make setup-kind\nkind delete cluster --name=kms || true\nDeleting cluster \"kms\" ...\nDeleted nodes: [\"kms-control-plane\"]\nkind create cluster --name=kms --config scripts/kind-config.yaml\nCreating cluster \"kms\" ...\n \u2713 Ensuring node image (kindest/node:v1.29.2) \ud83d\uddbc\n \u2713 Preparing nodes \ud83d\udce6\n \u2713 Writing configuration \ud83d\udcdc\n \u2713 Starting control-plane \ud83d\udd79\ufe0f\n \u2713 Installing CNI \ud83d\udd0c\n \u2713 Installing StorageClass \ud83d\udcbe\nSet kubectl context to \"kind-kms\"\nYou can now use your cluster with:\n\n# testing kubectl\n$&gt; kubectl get pod -A\nNAMESPACE            NAME                                        READY   STATUS    RESTARTS   AGE\nkube-system          coredns-76f75df574-7pzq4                    1/1     Running   0          17m\nkube-system          coredns-76f75df574-pkqrj                    1/1     Running   0          17m\nkube-system          etcd-kms-control-plane                      1/1     Running   0          17m\nkube-system          kindnet-w2hgj                               1/1     Running   0          17m\nkube-system          kube-apiserver-kms-control-plane            1/1     Running   0          17m\nkube-system          kube-controller-manager-kms-control-plane   1/1     Running   0          17m\nkube-system          kube-proxy-w66mx                            1/1     Running   0          17m\nkube-system          kube-scheduler-kms-control-plane            1/1     Running   0          17m\nkube-system          vault-kubernetes-kms-kms-control-plane      1/1     Running   0          17m\nlocal-path-storage   local-path-provisioner-7577fdbbfb-rmqq8     1/1     Running   0          17m\n\n# creating a kubernetes secret\n$&gt; kubectl create secret generic secret -n default --from-literal=key=value\nsecret/secret created\n\n# checking encryption value in etcd\n$&gt; kubectl -n kube-system exec etcd-kms-control-plane -- sh -c \"ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \\\n    --cert /etc/kubernetes/pki/etcd/server.crt \\\n    --key /etc/kubernetes/pki/etcd/server.key \\\n    --cacert /etc/kubernetes/pki/etcd/ca.crt \\\n    get /registry/secrets/default/secret\" | hexdump -C\n00000000  2f 72 65 67 69 73 74 72  79 2f 73 65 63 72 65 74  |/registry/secret|\n00000010  73 2f 64 65 66 61 75 6c  74 2f 73 65 63 72 65 74  |s/default/secret|\n00000020  2d 65 6e 63 72 79 70 74  65 64 0a 6b 38 73 3a 65  |-encrypted.k8s:e|\n00000030  6e 63 3a 6b 6d 73 3a 76  32 3a 76 61 75 6c 74 2d  |nc:kms:v2:vault-|\n00000040  6b 75 62 65 72 6e 65 74  65 73 2d 6b 6d 73 3a 0a  |kubernetes-kms:.|\n00000050  a4 02 7f fe e1 bb 63 29  71 62 b6 1f c0 be d5 a0  |......c)qb......|\n00000060  a8 38 0b e6 a1 bc 4b bb  16 ff 3f d3 3f 14 e4 be  |.8....K...?.?...|\n00000070  7e fa 53 de d5 06 75 08  3a fd 5f fb e9 a3 b1 29  |~.S...u.:._....)|\n00000080  e2 9f 26 1c ef bb 1b 24  37 bc f3 ab 9c df 46 c4  |..&amp;....$7.....F.|\n00000090  8f 47 33 e5 c0 76 54 3b  e7 f4 3b da 0d bf 80 e0  |.G3..vT;..;.....|\n000000a0  52 88 cd 1a 6f c6 ec 7f  bb 51 4b ef 0c c7 b6 8f  |R...o....QK.....|\n000000b0  31 2d 6b 96 3d 37 ee cb  f0 56 83 40 d8 b4 21 75  |1-k.=7...V.@..!u|\n000000c0  31 78 e7 ab ec 5f 6e f7  bf 84 86 34 2a aa 65 1b  |1x..._n....4*.e.|\n000000d0  8a 2b ce 6c ae 6f b6 df  11 5b ec 14 9d b9 00 74  |.+.l.o...[.....t|\n000000e0  9d 0c 01 11 c4 67 48 67  3d d3 8f 58 1a 0d da 34  |.....gHg=..X...4|\n000000f0  0d 55 19 91 cc 7e db c3  36 a2 6d 2f ea 28 10 ab  |.U...~..6.m/.(..|\n00000100  9b 1e 71 a9 d4 b1 74 6b  2f cc ef aa 30 d9 1a b8  |..q...tk/...0...|\n00000110  68 30 3b 5b c5 3a 32 69  6a 75 4d 43 68 1f 33 23  |h0;[.:2ijuMCh.3#|\n00000120  af 56 8c 15 c9 17 cb 8a  46 fc 9f 5a 24 da 25 16  |.V......F..Z$.%.|\n00000130  15 31 ce 41 59 6b b8 c6  7d 5e b3 ee 07 a7 65 3b  |.1.AYk..}^....e;|\n00000140  a8 f2 8a ab e7 d0 37 bc  9c e6 e6 33 71 57 c5 6c  |......7....3qW.l|\n00000150  09 ff e9 65 c9 8c 9f aa  1c e2 df a4 ad fc a0 02  |...e............|\n00000160  2b 6d 93 5e 44 20 64 28  d7 3f e1 98 eb 84 ab 22  |+m.^D d(.?.....\"|\n00000170  82 92 7a b6 b2 b8 12 0a  31 37 31 31 32 34 32 33  |..z.....17112423|\n00000180  36 34 1a 59 76 61 75 6c  74 3a 76 31 3a 6d 42 41  |64.Yvault:v1:mBA|\n00000190  4a 47 56 56 35 72 46 78  36 47 4c 4f 62 33 46 50  |JGVV5rFx6GLOb3FP|\n000001a0  37 4a 38 73 5a 79 4a 38  2f 68 36 61 48 2b 46 57  |7J8sZyJ8/h6aH+FW|\n000001b0  55 46 2f 67 53 68 30 65  41 31 4e 51 45 47 6e 30  |UF/gSh0eA1NQEGn0|\n000001c0  5a 30 38 66 6a 59 45 53  30 4c 31 79 35 45 49 50  |Z08fjYES0L1y5EIP|\n000001d0  33 67 4c 72 77 61 35 4b  61 44 35 43 63 28 01 0a  |3gLrwa5KaD5Cc(..|\n000001e0\n\n# receiving the secret\n$&gt;  kubectl get secret secret -o json | jq '.data | map_values(@base64d)'\n{\n  \"key\": \"value\"\n}\n</code></pre>"},{"location":"integration/","title":"Integrations","text":"<p>Collection of snippets to deploy the <code>vault-kubernetes-kms</code> plugin</p>"},{"location":"integration/#kubeadm","title":"kubeadm","text":"<ul> <li>https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/#kubeadm-k8s-io-v1beta3-ClusterConfiguration:</li> </ul> <pre><code>kind: ClusterConfiguration\napiServer:\n  extraArgs:\n    encryption-provider-config: \"/etc/kubernetes/encryption_provider_config_v2.yaml\"\n  extraVolumes:\n    - name: encryption-config\n      hostPath: \"/etc/kubernetes/encryption_provider_config_v2.yaml\"\n      mountPath: \"/etc/kubernetes/encryption_provider_config_v2.yaml\"\n      readOnly: true\n      pathType: File\n    - name: socket\n      hostPath: \"/opt/kms\"\n      mountPath: \"/opt/kms\"\n</code></pre>"},{"location":"integration/#kind","title":"kind","text":"<ul> <li>https://kind.sigs.k8s.io/docs/user/configuration/</li> </ul> <pre><code>kind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n  extraMounts:\n  # mount encryption provider config available on all cp nodes\n  - containerPath: /etc/kubernetes/encryption_provider_config_v2.yaml\n    hostPath: scripts/encryption_provider_config_v2.yml\n    readOnly: true\n    propagation: None\n  # vault-kubernetes-kms as a static Pod\n  - containerPath: /etc/kubernetes/manifests/vault-kubernetes-kms.yaml\n    hostPath: scripts/vault-kubernetes-kms.yml\n    readOnly: true\n    propagation: None\n  # patch kube-apiserver\n  kubeadmConfigPatches:\n    - |\n      kind: ClusterConfiguration\n      apiServer:\n        extraArgs:\n          encryption-provider-config: \"/etc/kubernetes/encryption_provider_config_v2.yaml\"\n        extraVolumes:\n        - name: encryption-config\n          hostPath: \"/etc/kubernetes/encryption_provider_config_v2.yaml\"\n          mountPath: \"/etc/kubernetes/encryption_provider_config_v2.yaml\"\n          readOnly: true\n          pathType: File\n        - name: socket\n          hostPath: \"/opt/kms\"\n          mountPath: \"/opt/kms\"\n</code></pre>"},{"location":"integration/#kops","title":"kops","text":"<ul> <li>https://kops.sigs.k8s.io/manifests_and_customizing_via_api/</li> </ul> <pre><code>kind: Cluster\nspec:\n  # patch kube-apiserver\n  encryptionConfig: true\n  # mount encryption provider config available on all cp nodes\n  fileAssets:\n    - name: scripts/encryption_provider_config_v2.yml\n      path: /etc/kubernetes/encryption_provider_config_v2.yaml\n      roles:\n        - Master\n      content: |\n        kind: EncryptionConfiguration\n        apiVersion: apiserver.config.k8s.io/v1\n        resources:\n        - resources:\n            - secrets\n            providers:\n            - kms:\n                apiVersion: v2\n                name: vault-kubernetes-kms\n                endpoint: unix:///opt/kms/vaultkms.socket\n            - identity: {}\n    # vault-kubernetes-kms as a static Pod\n    - name: scripts/vault-kubernetes-kms.yml\n      path: /etc/kubernetes/manifests/vault-kubernetes-kms.yaml\n      roles:\n        - Master\n      content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n        name: vault-kubernetes-kms\n        namespace: kube-system\n        spec:\n        priorityClassName: system-node-critical\n        hostNetwork: true\n        containers:\n            - name: vault-kubernetes-kms\n            image: falcosuessgott/vault-kubernetes-kms:latest\n            imagePullPolicy: IfNotPresent\n            command:\n                - /vault-kubernetes-kms\n                - -vault-address=http://172.17.0.1:8200\n                - -auth-method=token\n                - -token=root\n            volumeMounts:\n                # mount /opt/kms host directory\n                - name: kms\n                mountPath: /opt/kms\n            resources:\n                requests:\n                cpu: 100m\n                memory: 128Mi\n                limits:\n                cpu: \"2\"\n                memory: 1Gi\n        volumes:\n            # mount /opt/kms host directory\n            - name: kms\n            hostPath:\n                path: /opt/kms\n</code></pre>"},{"location":"metrics/","title":"Prometheus Metrics","text":"<p>Beginning with <code>v1.0.0</code> <code>vault-kubernetes-kms</code> exposes metrics under <code>:8080/metrics</code> (change with <code>-health-port</code> or setting <code>HEALTH_PORT</code>).</p> <p>The following metrics are available:</p>"},{"location":"metrics/#available-prometheus-metrics","title":"Available Prometheus Metrics","text":"Metric Name Type Description <code>vault_kubernetes_kms_decryption_operation_duration_seconds_bucket</code> Histogram duration of decryption operations in seconds <code>vault_kubernetes_kms_encryption_operation_duration_seconds_bucket</code> Histogram duration of encryption operations in seconds <code>vault_kubernetes_kms_decryption_operation_errors_total</code> Counter total number of errors during decryption operations <code>vault_kubernetes_kms_encryption_operation_errors_total</code> Counter total number of errors during encryption operations <code>vault_kubernetes_kms_token_expiry_seconds</code> Gauge time remaining until the current token expires <code>vault_kubernetes_kms_token_renewals_total</code> Counter total number of token renewals <p>Including the metrics defined in the Prometheus Process Collector (when running on <code>Linux</code>).</p> <p>Those metrics allow you to define your own Grafana Dashboard:</p> <p></p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>This Guide will walk you through the required steps of installing and configuring the <code>vault-kms-plugin</code> for Kubernetes. It currently uses token based authentication and HTTP communication, which is not secure enough when running in production.</p> <p>Tip</p> <p>Checkout https://falcosuessgott.github.io/hashicorp-vault-playground/home/ a project that helps you quickly setting up HashiCorp Vault locally with many useful Kubernetes Labs already pre configured.</p> <p>Warning</p> <p>This guide uses the new version of the Kubernetes KMS Plugin API, which was introduced in Kubernetes v1.29.0 (https://kubernetes.io/docs/tasks/administer-cluster/kms-provider/#kms-v2).</p>"},{"location":"quickstart/#requirements","title":"Requirements","text":"<p>In order to run this guide, you will need to have <code>kind</code>, <code>kubectl</code> and <code>vault</code> installed on your system. This guide has been tested on MacOS and Linux.</p> <p>Note</p> <p><code>vault-kubernetes-kms</code> is only published as <code>amd</code> (x86_64) images.</p> <p>You will make sure, you actually pull <code>amd</code> images. You can test it, by using <code>docker run -it ubuntu /usr/bin/uname -p</code> which, should output <code>86_64</code>.</p> <p>If you need <code>arm</code> images, raise an issue.</p>"},{"location":"quickstart/#clone-the-repository","title":"Clone the repository","text":"<pre><code>$&gt; git clone --depth 1 https://github.com/FalcoSuessgott/vault-kubernetes-kms.git\n$&gt; cd vault-kubernetes-kms\n</code></pre>"},{"location":"quickstart/#setup-a-vault-in-development-mode","title":"Setup a Vault in development mode","text":"<pre><code># invokes ./scripts/setup.vault.sh\n$&gt; make setup-vault\n\n# point your vault CLI to the local Vault server\n$&gt; export VAULT_ADDR=\"http://127.0.0.1:8200\"\n$&gt; export VAULT_SKIP_VERIFY=\"true\"\n$&gt; export VAULT_TOKEN=\"root\"\n$&gt; vault status\nKey             Value\n---             -----\nSeal Type       shamir\nInitialized     true\nSealed          false\nTotal Shares    1\nThreshold       1\nVersion         1.15.6\nBuild Date      2024-02-28T17:07:34Z\nStorage Type    inmem\nCluster Name    vault-cluster-32a0c10b\nCluster ID      2081a49b-8372-3857-3754-b576e0877682\nHA Enabled      false\n\n# a transit engine `transit` &amp; key `kms` has been created\n$&gt; vault list transit/keys\nKeys\n----\nkms\n</code></pre>"},{"location":"quickstart/#setup-vault-with-encryption-provider-config-usage","title":"setup vault with encryption provider config usage","text":"<p>Now, we have a local running Vault server, lets start a local running Kubernetes cluster using <code>kind</code>, which will deploy the <code>vault-kubernetes-kms</code> plugin as a static pod on the control plane as well as its required <code>encryption_provider_config</code> (see https://falcosuessgott.github.io/vault-kubernetes-kms/configuration/ for the required configuration steps):</p> <pre><code># can take up to 2 minutes\n$&gt; kind create cluster --name=kms --config assets/kind-config.yaml\nCreating cluster \"kms\" ...\n \u2713 Ensuring node image (kindest/node:v1.29.2) \ud83d\uddbc\n \u2713 Preparing nodes \ud83d\udce6\n \u2713 Writing configuration \ud83d\udcdc\n \u2713 Starting control-plane \ud83d\udd79\ufe0f\n \u2713 Installing CNI \ud83d\udd0c\n \u2713 Installing StorageClass \ud83d\udcbe\nSet kubectl context to \"kind-kms\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-kms\n\nHave a nice day! \ud83d\udc4b\n\n$&gt; kubectl get pod -n kube-system\nNAME                                        READY   STATUS    RESTARTS   AGE\ncoredns-76f75df574-q9nvb                    1/1     Running   0          97s\ncoredns-76f75df574-vwmxz                    1/1     Running   0          97s\netcd-kms-control-plane                      1/1     Running   0          2m\nkindnet-wngbr                               1/1     Running   0          98s\nkube-apiserver-kms-control-plane            1/1     Running   0          118s\nkube-controller-manager-kms-control-plane   1/1     Running   0          118s\nkube-proxy-rvl9z                            1/1     Running   0          98s\nkube-scheduler-kms-control-plane            1/1     Running   0          2m\nvault-kubernetes-kms-kms-control-plane      1/1     Running   0          116s # vaul-kubernetes-kms pod\n</code></pre>"},{"location":"quickstart/#creating-kubernetes-secrets-encrypted-on-etcd-disk","title":"Creating Kubernetes secrets encrypted on etcd disk","text":"<p>Time for creating new Kubernetes secrets and check how they are now stored in etcd storage due to a kms encryption provider configured:</p> <pre><code># create any secret\n$&gt; kubectl create secret generic secret-encrypted -n default --from-literal=key=value\nsecret/secret-encrypted created\n\n# show the secret\n\u00a7&gt;  kubectl get secret secret-encrypted -o json | jq '.data | map_values(@base64d)'\n{\n  \"key\": \"value\"\n}\n\n# show secret in etcd storage\n$&gt; kubectl -n kube-system exec etcd-kms-control-plane -- sh -c \"ETCDCTL_API=3 etcdctl \\\n    --endpoints=https://127.0.0.1:2379 \\\n    --cert /etc/kubernetes/pki/etcd/server.crt \\\n    --key /etc/kubernetes/pki/etcd/server.key \\\n    --cacert /etc/kubernetes/pki/etcd/ca.crt \\\n    get /registry/secrets/default/secret-encrypted\" | hexdump -C\n00000000  2f 72 65 67 69 73 74 72  79 2f 73 65 63 72 65 74  |/registry/secret|\n00000010  73 2f 64 65 66 61 75 6c  74 2f 73 65 63 72 65 74  |s/default/secret|\n00000020  2d 65 6e 63 72 79 70 74  65 64 0a 6b 38 73 3a 65  |-encrypted.k8s:e|\n00000030  6e 63 3a 6b 6d 73 3a 76  32 3a 76 61 75 6c 74 2d  |nc:kms:v2:vault-|\n00000040  6b 75 62 65 72 6e 65 74  65 73 2d 6b 6d 73 3a 0a  |kubernetes-kms:.|\n00000050  a4 02 7f fe e1 bb 63 29  71 62 b6 1f c0 be d5 a0  |......c)qb......|\n00000060  a8 38 0b e6 a1 bc 4b bb  16 ff 3f d3 3f 14 e4 be  |.8....K...?.?...|\n00000070  7e fa 53 de d5 06 75 08  3a fd 5f fb e9 a3 b1 29  |~.S...u.:._....)|\n00000080  e2 9f 26 1c ef bb 1b 24  37 bc f3 ab 9c df 46 c4  |..&amp;....$7.....F.|\n00000090  8f 47 33 e5 c0 76 54 3b  e7 f4 3b da 0d bf 80 e0  |.G3..vT;..;.....|\n000000a0  52 88 cd 1a 6f c6 ec 7f  bb 51 4b ef 0c c7 b6 8f  |R...o....QK.....|\n000000b0  31 2d 6b 96 3d 37 ee cb  f0 56 83 40 d8 b4 21 75  |1-k.=7...V.@..!u|\n000000c0  31 78 e7 ab ec 5f 6e f7  bf 84 86 34 2a aa 65 1b  |1x..._n....4*.e.|\n000000d0  8a 2b ce 6c ae 6f b6 df  11 5b ec 14 9d b9 00 74  |.+.l.o...[.....t|\n000000e0  9d 0c 01 11 c4 67 48 67  3d d3 8f 58 1a 0d da 34  |.....gHg=..X...4|\n000000f0  0d 55 19 91 cc 7e db c3  36 a2 6d 2f ea 28 10 ab  |.U...~..6.m/.(..|\n00000100  9b 1e 71 a9 d4 b1 74 6b  2f cc ef aa 30 d9 1a b8  |..q...tk/...0...|\n00000110  68 30 3b 5b c5 3a 32 69  6a 75 4d 43 68 1f 33 23  |h0;[.:2ijuMCh.3#|\n00000120  af 56 8c 15 c9 17 cb 8a  46 fc 9f 5a 24 da 25 16  |.V......F..Z$.%.|\n00000130  15 31 ce 41 59 6b b8 c6  7d 5e b3 ee 07 a7 65 3b  |.1.AYk..}^....e;|\n00000140  a8 f2 8a ab e7 d0 37 bc  9c e6 e6 33 71 57 c5 6c  |......7....3qW.l|\n00000150  09 ff e9 65 c9 8c 9f aa  1c e2 df a4 ad fc a0 02  |...e............|\n00000160  2b 6d 93 5e 44 20 64 28  d7 3f e1 98 eb 84 ab 22  |+m.^D d(.?.....\"|\n00000170  82 92 7a b6 b2 b8 12 0a  31 37 31 31 32 34 32 33  |..z.....17112423|\n00000180  36 34 1a 59 76 61 75 6c  74 3a 76 31 3a 6d 42 41  |64.Yvault:v1:mBA|  # encrypted value\n00000190  4a 47 56 56 35 72 46 78  36 47 4c 4f 62 33 46 50  |JGVV5rFx6GLOb3FP|\n000001a0  37 4a 38 73 5a 79 4a 38  2f 68 36 61 48 2b 46 57  |7J8sZyJ8/h6aH+FW|\n000001b0  55 46 2f 67 53 68 30 65  41 31 4e 51 45 47 6e 30  |UF/gSh0eA1NQEGn0|\n000001c0  5a 30 38 66 6a 59 45 53  30 4c 31 79 35 45 49 50  |Z08fjYES0L1y5EIP|\n000001d0  33 67 4c 72 77 61 35 4b  61 44 35 43 63 28 01 0a  |3gLrwa5KaD5Cc(..|\n000001e0\n</code></pre>"},{"location":"quickstart/#encrypt-all-existing-secrets","title":"Encrypt all existing secrets","text":"<p>You can encrypt all previous existing secrets using:</p> <pre><code>$&gt; kubectl get secrets --all-namespaces -o json | kubectl replace -f -\n</code></pre>"},{"location":"quickstart/#verify-decryption-after-restart","title":"Verify decryption after restart","text":"<p>If we restart the <code>kube-apiserver</code> the secrets have been Successfully decrypted:</p> <pre><code>$&gt; kubectl delete pod/etcd-kms-control-plane -n kube-system\npod \"kube-apiserver-minikube\" deleted\n\n# secret has been successfully decrypted\n$&gt; kubectl get secret secret-encrypted -o json | jq '.data | map_values(@base64d)'\n{\n  \"key\": \"value\"\n}\n</code></pre>"},{"location":"quickstart/#teardown","title":"Teardown","text":"<pre><code># kind cluster\n$&gt; kind delete cluster -n kms\n\n# vault\n$&gt; kill $(pgrep -x vault)\n</code></pre>"},{"location":"quickstart/#some-last-thoughts","title":"Some last thoughts","text":"<p>For production usage you should consider:</p> <ul> <li>use HTTPS for the communication between Kubernetes &amp; HashiCorp Vault (see https://falcosuessgott.github.io/vault-kubernetes-kms/configuration/)</li> <li>deploy the <code>vault-kubernetes-kms</code> plugin as a static pod on all control plane nodes</li> <li>automate the deployment using your preferred automation method (see https://falcosuessgott.github.io/vault-kubernetes-kms/integration/)</li> </ul>"},{"location":"sign/","title":"Artifact signing and SBOMs","text":"<p>Since <code>v0.2.0</code> <code>vault-kubernetes-kms</code> release artifacts are signed using <code>cosign</code>. We also publish a SBOMs.</p>"},{"location":"sign/#sboms","title":"SBOMs","text":"<p>SBOMs are published for every release. See https://github.com/FalcoSuessgott/vault-kubernetes-kms/releases</p>"},{"location":"sign/#verify-container-signatures","title":"Verify Container signatures","text":"<p><code>vault-kubernetes</code> Container Images are signed using <code>cosign</code> and ephemeral certificates signed during Github Actions runs. To verify a Container signature you can use the following oneliner:</p> <pre><code>$&gt; cosign verify ghcr.io/falcosuessgott/vault-kubernetes-kms:v0.2.1 \\\n  --certificate-identity=\"https://github.com/FalcoSuessgott/vault-kubernetes-kms/.github/workflows/goreleaser.yml@refs/tags/v0.2.1\" \\\n  --certificate-oidc-issuer=\"https://token.actions.githubusercontent.com\" | jq .\n\nVerification for ghcr.io/falcosuessgott/vault-kubernetes-kms:v0.2.1 --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - The code-signing certificate was verified using trusted certificate authority certificates\n[\n  {\n    \"critical\": {\n      \"identity\": {\n        \"docker-reference\": \"ghcr.io/falcosuessgott/vault-kubernetes-kms\"\n      },\n      \"image\": {\n        \"docker-manifest-digest\": \"sha256:f84b3e0acc178e1b8bcf13bb7868b93ef67b9fceff76ddfaaec85238dd026b31\"\n      },\n      \"type\": \"cosign container image signature\"\n    },\n    \"optional\": {\n      \"1.3.6.1.4.1.57264.1.1\": \"https://token.actions.githubusercontent.com\",\n      \"1.3.6.1.4.1.57264.1.2\": \"push\",\n      \"1.3.6.1.4.1.57264.1.3\": \"74d0643af3e6528bdb7346de4f046e509e50a115\",\n      \"1.3.6.1.4.1.57264.1.4\": \"goreleaser\",\n      \"1.3.6.1.4.1.57264.1.5\": \"FalcoSuessgott/vault-kubernetes-kms\",\n      \"1.3.6.1.4.1.57264.1.6\": \"refs/tags/v0.2.1\",\n      \"Bundle\": {\n        \"SignedEntryTimestamp\": \"MEUCID1CweAvlouvESD7+poEWehgdA4QGrSCk92BAFjdPEovAiEA+HipvN0melZl0/QjzHV7r3jgzibZ3gi0GsIIynhkrKo=\",\n        \"Payload\": {\n          \"body\": \"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\",\n          \"integratedTime\": 1723796362,\n          \"logIndex\": 121966596,\n          \"logID\": \"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d\"\n        }\n      },\n      \"Issuer\": \"https://token.actions.githubusercontent.com\",\n      \"Subject\": \"https://github.com/FalcoSuessgott/vault-kubernetes-kms/.github/workflows/goreleaser.yml@refs/tags/v0.2.1\",\n      \"githubWorkflowName\": \"goreleaser\",\n      \"githubWorkflowRef\": \"refs/tags/v0.2.1\",\n      \"githubWorkflowRepository\": \"FalcoSuessgott/vault-kubernetes-kms\",\n      \"githubWorkflowSha\": \"74d0643af3e6528bdb7346de4f046e509e50a115\",\n      \"githubWorkflowTrigger\": \"push\"\n    }\n  },\n  {\n    \"critical\": {\n      \"identity\": {\n        \"docker-reference\": \"ghcr.io/falcosuessgott/vault-kubernetes-kms\"\n      },\n      \"image\": {\n        \"docker-manifest-digest\": \"sha256:f84b3e0acc178e1b8bcf13bb7868b93ef67b9fceff76ddfaaec85238dd026b31\"\n      },\n      \"type\": \"cosign container image signature\"\n    },\n    \"optional\": {\n      \"1.3.6.1.4.1.57264.1.1\": \"https://token.actions.githubusercontent.com\",\n      \"1.3.6.1.4.1.57264.1.2\": \"push\",\n      \"1.3.6.1.4.1.57264.1.3\": \"74d0643af3e6528bdb7346de4f046e509e50a115\",\n      \"1.3.6.1.4.1.57264.1.4\": \"goreleaser\",\n      \"1.3.6.1.4.1.57264.1.5\": \"FalcoSuessgott/vault-kubernetes-kms\",\n      \"1.3.6.1.4.1.57264.1.6\": \"refs/tags/v0.2.1\",\n      \"Bundle\": {\n        \"SignedEntryTimestamp\": \"MEQCIGgxn2BBR1cXbokbpNQeA9WtLiAk5sf0qmcSsEwCzq6FAiB7D/epTTwqkJGmaPAa86e0DDksYxlEup190+EZU6wxKA==\",\n        \"Payload\": {\n          \"body\": \"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\",\n          \"integratedTime\": 1723796365,\n          \"logIndex\": 121966609,\n          \"logID\": \"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d\"\n        }\n      },\n      \"Issuer\": \"https://token.actions.githubusercontent.com\",\n      \"Subject\": \"https://github.com/FalcoSuessgott/vault-kubernetes-kms/.github/workflows/goreleaser.yml@refs/tags/v0.2.1\",\n      \"githubWorkflowName\": \"goreleaser\",\n      \"githubWorkflowRef\": \"refs/tags/v0.2.1\",\n      \"githubWorkflowRepository\": \"FalcoSuessgott/vault-kubernetes-kms\",\n      \"githubWorkflowSha\": \"74d0643af3e6528bdb7346de4f046e509e50a115\",\n      \"githubWorkflowTrigger\": \"push\"\n    }\n  }\n]\n</code></pre>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#rollback","title":"Rollback","text":"<p>-&gt; Follow the official Kubernetes documentation for decryption all data again.</p>"}]}